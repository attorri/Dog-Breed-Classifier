{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50787070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for the project\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import math\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03801fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for setting up path \n",
    "# The dataset downloads as \"Archives\", but I renamed it to \"Stanford_Dogs_Dataset\"\n",
    "dataset_path = \"/Users/christianattorri/downloads/Stanford_Dogs_Dataset\"\n",
    "\n",
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dec238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for preprocessing annotations \n",
    "\n",
    "for folder_name in os.listdir(os.path.join(dataset_path, \"annotations\", \"Annotation\")):\n",
    "    folder_path = os.path.join(dataset_path, \"annotations\", \"Annotation\", folder_name)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        for xml_file in os.listdir(folder_path):\n",
    "            xml_path = os.path.join(folder_path, xml_file)\n",
    "\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            filename = root.find(\"filename\").text\n",
    "            breed = root.find(\".//object/name\").text\n",
    "            width = int(root.find(\".//size/width\").text)\n",
    "            height = int(root.find(\".//size/height\").text)\n",
    "            xmin = int(root.find(\".//bndbox/xmin\").text)\n",
    "            ymin = int(root.find(\".//bndbox/ymin\").text)\n",
    "            xmax = int(root.find(\".//bndbox/xmax\").text)\n",
    "            ymax = int(root.find(\".//bndbox/ymax\").text)\n",
    "\n",
    "            data_list.append({\n",
    "                \"filename\": filename,\n",
    "                \"breed\": breed,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"xmin\": xmin,\n",
    "                \"ymin\": ymin,\n",
    "                \"xmax\": xmax,\n",
    "                \"ymax\": ymax\n",
    "            })\n",
    "\n",
    "annotations = pd.DataFrame(data_list)\n",
    "\n",
    "print(annotations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for preprocessing images\n",
    "\n",
    "def load_and_preprocess_images(df, images_folder, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        breed_name = row[\"breed\"]\n",
    "\n",
    "        filename_unfinished = row[\"filename\"].split('-')[0]\n",
    "        numeric_part = filename_unfinished.split('_')[0]\n",
    "\n",
    "        breed_folder = f\"{numeric_part}-{breed_name.replace(' ', '_')}\"\n",
    "        image_path = os.path.join(images_folder, breed_folder, row[\"filename\"] + \".jpg\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            img = load_img(image_path)\n",
    "            img = img.resize(target_size)  # I resized the images because the CNN needs input of the same size\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array / 255.0 \n",
    "            images.append(img_array)\n",
    "            labels.append(row[\"breed\"])\n",
    "\n",
    "            if len(images) < 3:\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Label: {row['breed']}\")\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "        except FileNotFoundError:\n",
    "            if (numeric_part != \"%s\" and breed_name not in [\"ottherhound\", \"English_foxhound\", \"French_bulldog\"]):\n",
    "                print(f\"Image not found: {image_path}\")\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "X, y = load_and_preprocess_images(annotations , os.path.join(dataset_path, \"images\", \"Images\"))\n",
    "\n",
    "\n",
    "print(\"Number of images:\", len(X))\n",
    "print(\"Image shape:\", X[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell For Label Encoding\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910c4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell for creating the model\n",
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(1024, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(2048, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a375ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for Image Data Generator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell For Training the Model\n",
    "\n",
    "max_batches_display = len(X_train) \n",
    "max_batches_process = len(X_train)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "batch_size = 32\n",
    "epochs = 20  \n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    with tqdm(total=min(max_batches_display, len(X_train)), unit='batch') as pbar:\n",
    "        steps_per_epoch = min(max_batches_process, math.ceil(len(X_train) / batch_size))\n",
    "        for _ in range(steps_per_epoch):\n",
    "            batch_X, batch_y = next(datagen.flow(X_train, y_train_encoded, batch_size=batch_size))\n",
    "            model.train_on_batch(batch_X, batch_y)\n",
    "            pbar.update(1)\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val_encoded, verbose=0)\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "    else:\n",
    "        print(\"Validation loss did not improve. Stopping training.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8621d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Cell\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_val_encoded, y_val_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198186e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val_encoded, y_val_pred_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for Final Evaluation on Test Set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
